{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(894, 40, 188)   (894,)\n",
      "(441, 40, 188)   (441,)\n",
      "New shape:  (40, 188, 1)\n",
      "['F' 'M']\n",
      "(894, 2)    (441, 2)\n",
      "['F' 'F' 'M' 'F' 'M' 'F' 'F' 'M' 'M']    [[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "Train on 894 samples, validate on 441 samples\n",
      "Epoch 1/50\n",
      "894/894 [==============================] - 2s 3ms/step - loss: 0.3635 - accuracy: 0.8971 - val_loss: 0.4478 - val_accuracy: 0.8594\n",
      "Epoch 2/50\n",
      "894/894 [==============================] - 2s 2ms/step - loss: 0.1869 - accuracy: 0.9407 - val_loss: 0.2005 - val_accuracy: 0.9252\n",
      "Epoch 3/50\n",
      "824/894 [==========================>...] - ETA: 0s - loss: 0.1026 - accuracy: 0.9672"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-149c69d1f575>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;31m#TRAIN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;31m#EVALUATION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/DL/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/DL/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/DL/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/DL/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import save\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten,Dropout,MaxPooling2D,BatchNormalization,AveragePooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "# Change TAG value to load different dataset\n",
    "# TAG == 0 MFCCS data\n",
    "# TAG == 1 SPECTROGAM data\n",
    "TAG = 0 # or 1\n",
    "\n",
    "if TAG == 0:\n",
    "    ds_spectro = np.load(\"ds_mfccs.npy\")\n",
    "if TAG == 1:\n",
    "    ds_spectro = np.load(\"ds_spectro.npy\")\n",
    "\n",
    "labels = np.load(\"labels.npy\")\n",
    "\n",
    "# shuffle trainset before splitting\n",
    "randomize = np.arange(len(ds_spectro))\n",
    "np.random.shuffle(randomize)\n",
    "ds_spectro = ds_spectro[randomize]\n",
    "labels = labels[randomize]\n",
    "\n",
    "# split trainset 70-30\n",
    "X_train_flat, X_test_flat, y_train_flat, y_test_flat = train_test_split( ds_spectro, labels, test_size = 0.33, random_state = 42)\n",
    "print(\"TRAIN: \", X_train_flat.shape, ' ', y_train_flat.shape)\n",
    "print(\"TEST: \",X_test_flat.shape, ' ', y_test_flat.shape)\n",
    "\n",
    "\n",
    "tot_train_examples = X_train_flat.shape[0]\n",
    "tot_test_examples = X_test_flat.shape[0]\n",
    "\n",
    "if TAG == 0:\n",
    "    width=40\n",
    "    height=188\n",
    "    \n",
    "if TAG == 1:\n",
    "    width = 129\n",
    "    height = 428\n",
    "\n",
    "channels = 1 # features channel\n",
    "f_size = 32 # filters\n",
    "\n",
    "Xtrain_reshaped = X_train_flat.reshape(tot_train_examples,width,height,channels)\n",
    "Xtest_reshaped = X_test_flat.reshape(tot_test_examples,width,height,channels)\n",
    "\n",
    "# LABEL array cast as cathegories\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train_flat)\n",
    "y_train_cat = le.transform(y_train_flat)\n",
    "y_test_cat = le.transform(y_test_flat)\n",
    "y_train_cat = to_categorical(y_train_cat, num_classes=2, dtype=\"float32\")\n",
    "y_test_cat = to_categorical(y_test_cat, num_classes=2, dtype=\"float32\")\n",
    "\n",
    "# CNN model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(f_size, kernel_size=3, strides=(2, 2), activation='relu', input_shape=(width,height,channels)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "f_size+=32\n",
    "model.add(Conv2D(f_size, kernel_size=3, activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "f_size-=48\n",
    "model.add(Conv2D(f_size, kernel_size=3, activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Optimizer\n",
    "epochs = 50\n",
    "batch_size = 8\n",
    "learning_rate = 0.01\n",
    "\n",
    "opt = Adam(learning_rate=learning_rate,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False)\n",
    "#opt = SGD(learning_rate=learning_rate, momentum=0.1, nesterov=False)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#TRAIN\n",
    "history = model.fit(Xtrain_reshaped, y_train_cat, validation_data=(Xtest_reshaped, y_test_cat), epochs=epochs,batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#EVALUATION\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
